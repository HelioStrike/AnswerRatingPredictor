{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from Vocab import *\n",
    "from model import AttentionModel\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparams\n",
    "lr = 1\n",
    "gamma = 0.95\n",
    "embed_size = 256\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = getVocab('text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = vocab.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionModel(embed_size, hidden_size, vocab_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sentences = pd.read_csv(\"data/qs.csv\")[\"Correct Answer\"]\n",
    "corr_sentences = [cleanText(sentence) for sentence in corr_sentences]\n",
    "corr_tensors = [torch.Tensor(vocab.getSentenceArray(sentence)) for sentence in corr_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = pd.read_csv(\"data/ratings.csv\")\n",
    "test_sentences[\"Answer\"] = [cleanText(s) for s in test_sentences[\"Answer\"]]\n",
    "orig_len = len(test_sentences[\"Answer\"])\n",
    "curr_len = orig_len\n",
    "\n",
    "for t in range(len(corr_sentences)):\n",
    "    for i in range(orig_len):\n",
    "        if t == test_sentences[\"Question Id\"][i]:\n",
    "            continue\n",
    "        test_sentences.loc[curr_len] = [t, test_sentences[\"Answer\"][i], 0]\n",
    "        curr_len += 1\n",
    "\n",
    "junk_sentences = pd.read_csv(\"data/wat.csv\")\n",
    "junk_sentences[\"Answer\"] = [cleanText(sentence) for sentence in junk_sentences[\"Answer\"]]\n",
    "\n",
    "for t in range(len(corr_sentences)):\n",
    "    for i in range(len(junk_sentences)):\n",
    "        test_sentences.loc[curr_len] = [t, junk_sentences[\"Answer\"][i], junk_sentences[\"Rating\"][i]]\n",
    "        curr_len += 1\n",
    "\n",
    "test_tensors = [torch.tensor(vocab.getSentenceArray(s)) for s in test_sentences[\"Answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krypt/myStuff/pytorch/AnswerRatingPredictor/model.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  corr_attn_params = F.softmax(self.lin_attn(corr).view(1, -1))\n",
      "/home/krypt/myStuff/pytorch/AnswerRatingPredictor/model.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  test_attn_params = F.softmax(self.lin_attn(test).view(1, -1))\n",
      "/home/krypt/.local/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 7.208067096100422\n",
      "Epoch: 1 Loss: 2.3477790712789144\n",
      "Epoch: 2 Loss: 2.0201978877786964\n",
      "Epoch: 3 Loss: 0.45836878943720216\n",
      "Epoch: 4 Loss: 0.9588308176125836\n",
      "Epoch: 5 Loss: 0.8678273036152128\n",
      "Epoch: 6 Loss: 0.5046980311352244\n",
      "Epoch: 7 Loss: 0.4290146143901121\n",
      "Epoch: 8 Loss: 0.22037911791845932\n",
      "Epoch: 9 Loss: 0.42299654405423937\n",
      "Epoch: 10 Loss: 0.31762334021450567\n",
      "Epoch: 11 Loss: 0.17638741635291266\n",
      "Epoch: 12 Loss: 0.10876714583976055\n",
      "Epoch: 13 Loss: 0.09312791810757926\n",
      "Epoch: 14 Loss: 0.13325239164253144\n",
      "Epoch: 15 Loss: 0.1844676444470854\n",
      "Epoch: 16 Loss: 0.16262580969351914\n",
      "Epoch: 17 Loss: 0.17011783394080893\n",
      "Epoch: 18 Loss: 0.1278219599132031\n",
      "Epoch: 19 Loss: 0.13400344196672886\n",
      "Epoch: 20 Loss: 0.10289015082185404\n",
      "Epoch: 21 Loss: 0.10528241058117305\n",
      "Epoch: 22 Loss: 0.055690942236058305\n",
      "Epoch: 23 Loss: 0.0372847970136313\n",
      "Epoch: 24 Loss: 0.07045631022822674\n",
      "Epoch: 25 Loss: 0.11170079905184316\n",
      "Epoch: 26 Loss: 0.018662667857845983\n",
      "Epoch: 27 Loss: 0.04454281843790686\n",
      "Epoch: 28 Loss: 0.011642756829264578\n",
      "Epoch: 29 Loss: 0.06845118668308009\n",
      "Epoch: 30 Loss: 0.10868730268089177\n",
      "Epoch: 31 Loss: 0.11113019898955839\n",
      "Epoch: 32 Loss: 0.06945769896424453\n",
      "Epoch: 33 Loss: 0.021761960593847107\n",
      "Epoch: 34 Loss: 0.02910854392435469\n",
      "Epoch: 35 Loss: 0.09855330728608233\n",
      "Epoch: 36 Loss: 0.06831830210864798\n",
      "Epoch: 37 Loss: 0.06866497305308761\n",
      "Epoch: 38 Loss: 0.14451591899844204\n",
      "Epoch: 39 Loss: 0.05926573051637973\n",
      "Epoch: 40 Loss: 0.057251856601693185\n",
      "Epoch: 41 Loss: 0.05478272571118503\n",
      "Epoch: 42 Loss: 0.08101321993057722\n",
      "Epoch: 43 Loss: 0.09427951026406253\n",
      "Epoch: 44 Loss: 0.09479853982868286\n",
      "Epoch: 45 Loss: 0.06301761551026192\n",
      "Epoch: 46 Loss: 0.09575693338188526\n",
      "Epoch: 47 Loss: 0.029776512798823124\n",
      "Epoch: 48 Loss: 0.057231886849883395\n",
      "Epoch: 49 Loss: 0.050742054009295656\n",
      "Epoch: 50 Loss: 0.09916212860018192\n",
      "Epoch: 51 Loss: 0.02711441063269973\n",
      "Epoch: 52 Loss: 0.055374877092458946\n",
      "Epoch: 53 Loss: 0.014999987034348045\n",
      "Epoch: 54 Loss: 0.02155656120095034\n",
      "Epoch: 55 Loss: 0.04876022716337575\n",
      "Epoch: 56 Loss: 0.010298558954834502\n",
      "Epoch: 57 Loss: 0.05765655687368865\n",
      "Epoch: 58 Loss: 0.009576358170296673\n",
      "Epoch: 59 Loss: 0.08679364432213388\n",
      "Epoch: 60 Loss: 0.09427841390782826\n",
      "Epoch: 61 Loss: 0.05771279338991489\n",
      "Epoch: 62 Loss: 0.059107821890245216\n",
      "Epoch: 63 Loss: 0.05363060697104419\n",
      "Epoch: 64 Loss: 0.06485878529772982\n",
      "Epoch: 65 Loss: 0.05690779977185652\n",
      "Epoch: 66 Loss: 0.09680936469869342\n",
      "Epoch: 67 Loss: 0.09849802005255248\n",
      "Epoch: 68 Loss: 0.019783042589027355\n",
      "Epoch: 69 Loss: 0.05696026359064005\n",
      "Epoch: 70 Loss: 0.05639131600078323\n",
      "Epoch: 71 Loss: 0.05609871024375809\n",
      "Epoch: 72 Loss: 0.054207142975229106\n",
      "Epoch: 73 Loss: 0.06835114567224965\n",
      "Epoch: 74 Loss: 0.09508512332091147\n",
      "Epoch: 75 Loss: 0.008552353685075065\n",
      "Epoch: 76 Loss: 0.057425478655427686\n",
      "Epoch: 77 Loss: 0.058630956719675276\n",
      "Epoch: 78 Loss: 0.03406826139196567\n",
      "Epoch: 79 Loss: 0.057663823011291915\n",
      "Epoch: 80 Loss: 0.13629661776464164\n",
      "Epoch: 81 Loss: 0.10743824374107208\n",
      "Epoch: 82 Loss: 0.016069477380485475\n",
      "Epoch: 83 Loss: 0.05841151450670316\n",
      "Epoch: 84 Loss: 0.08758828890540549\n",
      "Epoch: 85 Loss: 0.0953805792027872\n",
      "Epoch: 86 Loss: 0.13511971291458214\n",
      "Epoch: 87 Loss: 0.019341737877738407\n",
      "Epoch: 88 Loss: 0.12601323293389555\n",
      "Epoch: 89 Loss: 0.05630059902196288\n",
      "Epoch: 90 Loss: 0.03650780068184345\n",
      "Epoch: 91 Loss: 0.04593245960093249\n",
      "Epoch: 92 Loss: 0.05427933550503991\n",
      "Epoch: 93 Loss: 0.05674307610852347\n",
      "Epoch: 94 Loss: 0.09501516122752095\n",
      "Epoch: 95 Loss: 0.005208772690162622\n",
      "Epoch: 96 Loss: 0.04690162383337623\n",
      "Epoch: 97 Loss: 0.019695809837705747\n",
      "Epoch: 98 Loss: 0.009694293154330624\n",
      "Epoch: 99 Loss: 0.08976614395654514\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    total_loss = 0\n",
    "    for t in range(len(test_tensors)):\n",
    "        curr_a = random.randint(0, len(test_tensors)-1) \n",
    "        curr_q = test_sentences[\"Question Id\"][curr_a]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(corr_tensors[curr_q].long(), test_tensors[curr_a].long()).view(1)\n",
    "        y = torch.tensor(test_sentences[\"Rating\"][curr_a]).float().view(1)\n",
    "        loss = criterion(pred, y)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= gamma\n",
    "        \n",
    "    print(\"Epoch:\", e, \"Loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"saved_models/model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     Question Id                                             Answer  Rating\n",
       "0             0             encapsulation polymorphism inheritance     0.7\n",
       "1             0  the main features of oop are encapsulation pol...     1.0\n",
       "2             1  the main advantage of oop is better manageable...     1.0\n",
       "3             1  the main advantage of oop is better manageable...     0.3\n",
       "4             2  encapsulation is referred to one of the follow...     1.0\n",
       "5             2             it is data hiding and bundling of data     0.5\n",
       "6             3  polymorphism means that some code or operation...     1.0\n",
       "7             3  it is a feature that allows a single object to...     0.9\n",
       "8             4  a class is based on another class and uses dat...     1.0\n",
       "9             4           the purpose of inheritance is code reuse     0.2\n",
       "10            5  it stands for java development kit it is the t...     1.0\n",
       "11            5                 it stands for java development kit     0.7\n",
       "12            5                               java development kit     0.5\n",
       "13            0  the main advantage of oop is better manageable...     0.0\n",
       "14            0  the main advantage of oop is better manageable...     0.0\n",
       "15            0  encapsulation is referred to one of the follow...     0.0\n",
       "16            0             it is data hiding and bundling of data     0.0\n",
       "17            0  polymorphism means that some code or operation...     0.0\n",
       "18            0  it is a feature that allows a single object to...     0.0\n",
       "19            0  a class is based on another class and uses dat...     0.0\n",
       "20            0           the purpose of inheritance is code reuse     0.0\n",
       "21            0  it stands for java development kit it is the t...     0.0\n",
       "22            0                 it stands for java development kit     0.0\n",
       "23            0                               java development kit     0.0\n",
       "24            1             encapsulation polymorphism inheritance     0.0\n",
       "25            1  the main features of oop are encapsulation pol...     0.0\n",
       "26            1  encapsulation is referred to one of the follow...     0.0\n",
       "27            1             it is data hiding and bundling of data     0.0\n",
       "28            1  polymorphism means that some code or operation...     0.0\n",
       "29            1  it is a feature that allows a single object to...     0.0\n",
       "..          ...                                                ...     ...\n",
       "66            4                 it stands for java development kit     0.0\n",
       "67            4                               java development kit     0.0\n",
       "68            5             encapsulation polymorphism inheritance     0.0\n",
       "69            5  the main features of oop are encapsulation pol...     0.0\n",
       "70            5  the main advantage of oop is better manageable...     0.0\n",
       "71            5  the main advantage of oop is better manageable...     0.0\n",
       "72            5  encapsulation is referred to one of the follow...     0.0\n",
       "73            5             it is data hiding and bundling of data     0.0\n",
       "74            5  polymorphism means that some code or operation...     0.0\n",
       "75            5  it is a feature that allows a single object to...     0.0\n",
       "76            5  a class is based on another class and uses dat...     0.0\n",
       "77            5           the purpose of inheritance is code reuse     0.0\n",
       "78            0                                        i dont know     0.1\n",
       "79            0            i dont know the answer to that question     0.2\n",
       "80            0                                         its a goal     0.0\n",
       "81            1                                        i dont know     0.1\n",
       "82            1            i dont know the answer to that question     0.2\n",
       "83            1                                         its a goal     0.0\n",
       "84            2                                        i dont know     0.1\n",
       "85            2            i dont know the answer to that question     0.2\n",
       "86            2                                         its a goal     0.0\n",
       "87            3                                        i dont know     0.1\n",
       "88            3            i dont know the answer to that question     0.2\n",
       "89            3                                         its a goal     0.0\n",
       "90            4                                        i dont know     0.1\n",
       "91            4            i dont know the answer to that question     0.2\n",
       "92            4                                         its a goal     0.0\n",
       "93            5                                        i dont know     0.1\n",
       "94            5            i dont know the answer to that question     0.2\n",
       "95            5                                         its a goal     0.0\n",
       "\n",
       "[96 rows x 3 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
